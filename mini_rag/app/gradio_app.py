from dotenv import load_dotenv; load_dotenv()
import os, json, time
import gradio as gr
from pathlib import Path
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from app.prompts import RAG_PROMPT
from core.indexer import build_or_load_vectorstore, rebuild_vectorstore
from core.rag import make_qa
from core.vision import analyze_image_or_ocr

# OpenMP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶©ëŒ ë¬¸ì œ í•´ê²°
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

ROOT = Path(__file__).resolve().parents[1]
DRIVE_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID", "")
SHARED_FOLDER_ID = os.getenv("SHARED_FOLDER_ID", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

class RagApp:
    def __init__(self):
        self.vs = None
        self.qa = None
        self.k = 5
        self.last_info = ""

    def ensure(self, drive_folder: str = "", shared_folder: str = "", force: bool = False):
        t0 = time.time()
        self.vs = rebuild_vectorstore(drive_folder, shared_folder) \
            if force else build_or_load_vectorstore(drive_folder, shared_folder)
        self.qa = make_qa(self.vs, k=self.k, prompt=RAG_PROMPT, model=OPENAI_MODEL)
        folder_info = f"drive={drive_folder}, shared={shared_folder}" \
            if drive_folder and shared_folder else (drive_folder or shared_folder)
        self.last_info = f"index ready k={self.k} folders={folder_info} ({time.time()-t0:.1f}s)"
        return self.last_info

    def set_k(self, k:int):
        self.k = int(k)
        if self.vs:
            self.qa = make_qa(self.vs, k=self.k, prompt=RAG_PROMPT, model=OPENAI_MODEL)
        return f"k={self.k} ì ìš©"

    def ask(self, msg:str, history):
        if not self.qa: self.ensure(DRIVE_FOLDER_ID, SHARED_FOLDER_ID, force=False)
        resp = self.qa.invoke({"query": msg})
        ans = resp.get("result","").strip()
        srcs = resp.get("source_documents",[]) or []
        lines = []
        for i,d in enumerate(srcs[:3],1):
            m = d.metadata or {}
            lines.append(f"{i}. {m.get('gdrive_name','?')} (id={m.get('gdrive_id','?')}) p.{m.get('page','?')}")
        if lines: ans += "\n\n[ì°¸ê³  ë¬¸ì„œ]\n" + "\n".join(lines)
        return ans

app = RagApp()

with gr.Blocks(title="AWS Diagram RAG") as demo:
    gr.Markdown("### AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ í•´ì„¤")
    with gr.Row():
        drive_fid = gr.Textbox(value=DRIVE_FOLDER_ID, label="Drive Folder ID", scale=1)
        shared_fid = gr.Textbox(value=SHARED_FOLDER_ID, label="Shared Folder ID", scale=2)
        k_slider = gr.Slider(1,10,value=5,step=1,label="Top-K", scale=1)
    with gr.Row():
        btn_build = gr.Button("ì¸ë±ìŠ¤(ì¬)êµ¬ì¶•")
        stat = gr.Markdown("")

    # RAG íƒ­
    with gr.Tab("RAG Q&A"):
        chat = gr.Chatbot(type="messages", height=420, label="LLM í•´ì„¤")
        msg = gr.Textbox(placeholder="ì˜ˆ) ë°ì´í„° íë¦„ì„ ì„¤ëª…í•´ì¤˜")
        send = gr.Button("ì „ì†¡", variant="primary")
        clear = gr.Button("ëŒ€í™” ì§€ìš°ê¸°")

    # ì´ë¯¸ì§€ í•´ì„ íƒ­
    with gr.Tab("ì´ë¯¸ì§€ í•´ì„"):
        gr.Markdown("""
        ### ğŸ“‹ ì‚¬ìš© ë°©ë²•
        1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. **OCR ë³´ê°•**: ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ë ¤ë©´ ì²´í¬í•˜ì„¸ìš”
        3. **ì•„ì´ì½˜ ì •ë³´**: AWS ì„œë¹„ìŠ¤ ì•„ì´ì½˜ê³¼ ì—°ê²° ê´€ê³„ë¥¼ JSONìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)
        4. **ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸**: ë‹¤ì´ì–´ê·¸ë¨ì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­)
        5. **ì´ë¯¸ì§€ í•´ì„**: ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”
        """)
        
        img_in = gr.Image(type="pil", label="ë‹¤ì´ì–´ê·¸ë¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        use_ocr = gr.Checkbox(value=True, label="OCR ë³´ê°•")
        
        # ì•„ì´ì½˜ íƒì§€ JSON ì˜ˆì‹œ
        icon_json_example = '''{
  "icons": [
    {
      "type": "aws_service",
      "name": "Amazon S3",
      "confidence": 0.95,
      "bbox": [100, 150, 200, 250],
      "description": "Simple Storage Service - ê°ì²´ ì €ì¥ì†Œ"
    },
    {
      "type": "aws_service", 
      "name": "AWS Lambda",
      "confidence": 0.92,
      "bbox": [300, 200, 400, 300],
      "description": "Serverless compute service - ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ…"
    },
    {
      "type": "aws_service",
      "name": "Amazon CloudFront",
      "confidence": 0.88,
      "bbox": [50, 100, 150, 200],
      "description": "Content Delivery Network - CDN ì„œë¹„ìŠ¤"
    }
  ],
  "connections": [
    {
      "from": "Amazon CloudFront",
      "to": "Amazon S3",
      "type": "origin",
      "description": "CloudFrontê°€ S3ë¥¼ ì˜¤ë¦¬ì§„ìœ¼ë¡œ ì‚¬ìš©"
    },
    {
      "from": "Amazon S3",
      "to": "AWS Lambda",
      "type": "trigger",
      "description": "S3 ì´ë²¤íŠ¸ê°€ Lambda í•¨ìˆ˜ë¥¼ íŠ¸ë¦¬ê±°"
    }
  ],
  "metadata": {
    "diagram_type": "architecture",
    "region": "us-east-1",
    "description": "ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜"
  }
}'''
        
        icon_json = gr.Textbox(
            value=icon_json_example,
            label="ì•„ì´ì½˜ íƒì§€ JSON(ì„ íƒ)", 
            lines=12,
            placeholder="AWS ì„œë¹„ìŠ¤ ì•„ì´ì½˜ê³¼ ì—°ê²° ê´€ê³„ë¥¼ JSON í˜•íƒœë¡œ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        gr.Markdown("""
        **ğŸ’¡ JSON í˜•ì‹ ê°€ì´ë“œ:**
        - `icons`: AWS ì„œë¹„ìŠ¤ ì•„ì´ì½˜ ëª©ë¡
          - `type`: "aws_service" (ê³ ì •ê°’)
          - `name`: ì„œë¹„ìŠ¤ ì´ë¦„ (ì˜ˆ: "Amazon S3", "AWS Lambda")
          - `confidence`: ì‹ ë¢°ë„ (0.0~1.0)
          - `bbox`: [x1, y1, x2, y2] ì¢Œí‘œ (ì„ íƒì‚¬í•­)
          - `description`: ì„œë¹„ìŠ¤ ì„¤ëª…
        - `connections`: ì„œë¹„ìŠ¤ ê°„ ì—°ê²° ê´€ê³„
          - `from`: ì¶œë°œ ì„œë¹„ìŠ¤ëª…
          - `to`: ë„ì°© ì„œë¹„ìŠ¤ëª…  
          - `type`: ì—°ê²° ìœ í˜• (ì˜ˆ: "trigger", "origin", "target")
          - `description`: ì—°ê²° ì„¤ëª…
        - `metadata`: ë‹¤ì´ì–´ê·¸ë¨ ë©”íƒ€ë°ì´í„° (ì„ íƒì‚¬í•­)
        """)
        
        # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì˜ˆì‹œ
        extra_ctx_example = '''ì´ ë‹¤ì´ì–´ê·¸ë¨ì€ AWS ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
- ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ S3ì— ì €ì¥ë©ë‹ˆë‹¤
- S3 ì´ë²¤íŠ¸ê°€ Lambda í•¨ìˆ˜ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤
- LambdaëŠ” ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë‹¤ë¥¸ S3 ë²„í‚·ì— ì €ì¥í•©ë‹ˆë‹¤

ì´ ì‹œìŠ¤í…œì˜ ëª©ì ì€ ìë™í™”ëœ ì´ë¯¸ì§€ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬í˜„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì¶”ê°€ ì •ë³´:
- ì²˜ë¦¬ ëŒ€ìƒ: ì‚¬ìš©ì ì—…ë¡œë“œ ì´ë¯¸ì§€
- ì²˜ë¦¬ ë°©ì‹: ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜
- í™•ì¥ì„±: ìë™ ìŠ¤ì¼€ì¼ë§ ì§€ì›'''
        
        extra_ctx = gr.Textbox(
            value=extra_ctx_example,
            label="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸(ì„ íƒ)", 
            lines=8,
            placeholder="ë‹¤ì´ì–´ê·¸ë¨ì— ëŒ€í•œ ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        gr.Markdown("""
        **ğŸ’¡ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì‘ì„± íŒ:**
        - ì‹œìŠ¤í…œì˜ ëª©ì ê³¼ ê¸°ëŠ¥ì„ ì„¤ëª…í•˜ì„¸ìš”
        - ì£¼ìš” êµ¬ì„± ìš”ì†Œì™€ ì—­í• ì„ ë‚˜ì—´í•˜ì„¸ìš”
        - ë°ì´í„° íë¦„ê³¼ ì²˜ë¦¬ ê³¼ì •ì„ ì„¤ëª…í•˜ì„¸ìš”
        - ê¸°ìˆ ì  íŠ¹ì§•ì´ë‚˜ ì œì•½ì‚¬í•­ì„ ì–¸ê¸‰í•˜ì„¸ìš”
        - ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì´ë‚˜ ì‚¬ìš© ì‚¬ë¡€ë¥¼ í¬í•¨í•˜ì„¸ìš”
        """)
        
        run_img = gr.Button("ì´ë¯¸ì§€ í•´ì„", variant="primary")
        out_json = gr.Code(label="êµ¬ì¡°í™” JSON")
        out_expl = gr.Markdown(label="í•´ì„¤")

    def on_build(drive_fid, shared_fid, k):
        try:
            # í´ë” ID ê²€ì¦
            if not drive_fid and not shared_fid:
                return "âŒ Drive Folder ID ë˜ëŠ” Shared Folder ID ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
            
            app.set_k(int(k))
            result = app.ensure(drive_fid, shared_fid, force=True)
            return f"âœ… {result}"
        except Exception as e:
            error_msg = f"âŒ ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {str(e)}"
            print(error_msg)
            return error_msg

    def on_send(message, history, drive_fid, shared_fid, k):
        if not message: 
            return "", history
        try:
            app.set_k(int(k))
            if not app.qa: 
                app.ensure(drive_fid or DRIVE_FOLDER_ID, shared_fid or SHARED_FOLDER_ID, force=False)
            answer = app.ask(message, history)
            history = history + [
                {"role":"user","content":message},
                {"role":"assistant","content":answer},
            ]
            return "", history
        except Exception as e:
            error_msg = f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
            print(error_msg)
            history = history + [
                {"role":"user","content":message},
                {"role":"assistant","content":error_msg},
            ]
            return "", history

    def on_img(img, ocr_flag, icon_json_str, extra):
        raw = analyze_image_or_ocr(img, ocr=ocr_flag, icon_json=icon_json_str, extra_context=extra)
        # JSON ë¸”ë¡ ë¶„ë¦¬ ì‹œë„
        jtxt, rest = "{}", raw
        try:
            fb = raw.find("{"); lb = raw.rfind("}")
            cand = raw[fb:lb+1] if fb!=-1 and lb!=-1 else "{}"
            jtxt = json.dumps(json.loads(cand), ensure_ascii=False, indent=2)
            rest = raw[lb+1:].strip() if lb+1 < len(raw) else ""
        except: pass
        return jtxt, (rest or "ìƒë‹¨ì˜ êµ¬ì¡° JSON í™•ì¸")

    btn_build.click(on_build, inputs=[drive_fid, shared_fid, k_slider], outputs=[stat])
    k_slider.release(lambda k: app.set_k(int(k)), inputs=[k_slider], outputs=[stat])
    send.click(on_send, inputs=[msg, chat, drive_fid, shared_fid, k_slider], outputs=[msg, chat])
    msg.submit(on_send, inputs=[msg, chat, drive_fid, shared_fid, k_slider], outputs=[msg, chat])
    clear.click(lambda: [], None, chat, queue=False)

if __name__ == "__main__":
    try: app.ensure(DRIVE_FOLDER_ID, SHARED_FOLDER_ID, force=False)
    except Exception as e: print("[init warn]", e)
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)