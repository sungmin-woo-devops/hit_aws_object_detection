# app_gradio.py
# pip install gradio langchain langchain-community langchain-openai google-api-python-client google-auth-httplib2 google-auth-oauthlib faiss-cpu pymupdf python-dotenv

from dotenv import load_dotenv; load_dotenv()
import os, io, json, pathlib, time
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import gradio as gr
import PIL.Image as Image

from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from google.oauth2.credentials import Credentials as UserCreds
from google.oauth2.service_account import Credentials as SvcCreds
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow

from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_core.prompts import ChatPromptTemplate

# Vision ëª¨ë“ˆ import
from core.vision import analyze_image, analyze_image_or_ocr, analyze_aws_architecture

# ========= ê¸°ë³¸ ì„¤ì • =========
ROOT = Path(__file__).parent
SCOPES = ["https://www.googleapis.com/auth/drive.readonly"]
CRED_JSON = ROOT / "credentials.json"     # installed ë˜ëŠ” service_account ë‘˜ ë‹¤ ì§€ì›
TOKEN_PATH = ROOT / "token.json"
OUTDIR = ROOT / "data" / "raw"
INDEX_DIR = ROOT / "index"                # FAISS ìºì‹œ ì €ì¥ ê²½ë¡œ
INDEX_DIR.mkdir(parents=True, exist_ok=True)
OUTDIR.mkdir(parents=True, exist_ok=True)

FOLDER_ID = os.getenv("FOLDER_ID") or "1mEb4WtWpO0LeVd3Sgzs4pyQxnt4kbhET"  # í•„ìš” ì‹œ .envë¡œ ì§€ì •
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# ========= ê³µìš© í”„ë¡¬í”„íŠ¸ =========
PROMPT = ChatPromptTemplate.from_messages([
    ("system",
     """ë‹¹ì‹ ì€ AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ í•´ì„¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.

1) ì—­í• ê³¼ ê´€ê³„: ê° ì„œë¹„ìŠ¤ì˜ ì—­í• ê³¼ ì„œë¹„ìŠ¤ ê°„ ì—°ê²°/ë°ì´í„° íë¦„ì„ ë‹¨ê³„ë³„ë¡œ.
2) ì•„í‚¤í…ì²˜ ëª©ì  ë¶„ì„: ìš©ë„(ì›¹/ë°ì´í„°/ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë“±), ì¥ì /ìœ ì˜ì .
3) ì¶œë ¥ í˜•ì‹:
   - êµ¬ì„± ìš”ì†Œ í•´ì„¤
   - ë°ì´í„° íë¦„
   - ì¶”ê°€ ë¶„ì„(ì„±ëŠ¥/ë³´ì•ˆ/í™•ì¥ì„±)
4) ì œí•œ: ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” "ì œê³µëœ ì •ë³´ë¡œëŠ” í™•ì¸ ë¶ˆê°€"ë¼ê³  ëª…ì‹œ.
ë¶ˆí•„ìš”í•œ ì„œë¡  ì—†ì´ í•µì‹¬ë¶€í„° ì œì‹œ.
"""),
    ("human", "ì§ˆë¬¸: {question}\n\nì»¨í…ìŠ¤íŠ¸: {context}")
])

# ========= ìê²© ë¡œë” (installed / service_account ìë™ ë¶„ê¸°) =========
def load_creds_auto(json_path: pathlib.Path, scopes) -> object:
    data = json.loads(json_path.read_text(encoding="utf-8"))
    t = data.get("type")
    if t == "service_account":
        return SvcCreds.from_service_account_file(str(json_path), scopes=scopes)
    if "installed" in data or "web" in data:
        creds = None
        if TOKEN_PATH.exists():
            creds = UserCreds.from_authorized_user_file(str(TOKEN_PATH), scopes)
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(str(json_path), scopes)
                creds = flow.run_local_server(port=0)
            TOKEN_PATH.write_text(creds.to_json(), encoding="utf-8")
        return creds
    raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” credentials.json í˜•ì‹ì…ë‹ˆë‹¤.")

def build_drive():
    creds = load_creds_auto(CRED_JSON, SCOPES)
    return build("drive", "v3", credentials=creds)

# ========= ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ =========
def fetch_pdfs_from_drive(folder_id: str) -> List[Dict]:
    drive = build_drive()
    # í´ë” ë©”íƒ€
    meta = drive.files().get(fileId=folder_id, fields="id,name,mimeType,driveId").execute()
    is_shared = bool(meta.get("driveId"))
    params = {
        "q": f"'{folder_id}' in parents and mimeType='application/pdf' and trashed=false",
        "fields": "nextPageToken, files(id,name,mimeType,parents,modifiedTime)",
        "includeItemsFromAllDrives": True,
        "supportsAllDrives": True,
        "pageSize": 1000,
    }
    if is_shared:
        params.update({"corpora": "drive", "driveId": meta["driveId"]})

    files, token = [], None
    while True:
        if token: params["pageToken"] = token
        r = drive.files().list(**params).execute()
        files.extend(r.get("files", []))
        token = r.get("nextPageToken")
        if not token: break
    return files

def download_pdf(file_id: str, filename: str) -> pathlib.Path:
    drive = build_drive()
    outpath = OUTDIR / filename
    if outpath.exists():
        return outpath
    
    request = drive.files().get_media(fileId=file_id)
    with open(outpath, "wb") as f:
        downloader = MediaIoBaseDownload(f, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()
    return outpath

def process_pdf(pdf_path: pathlib.Path) -> List[Document]:
    loader = PyMuPDFLoader(str(pdf_path))
    pages = loader.load()
    
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        separators=["\n\n", "\n", " ", ""]
    )
    return splitter.split_documents(pages)

def build_or_load_vectorstore(folder_id: str) -> Tuple[FAISS, int]:
    index_path = INDEX_DIR / f"faiss_{folder_id}"
    
    if index_path.exists():
        print(f"ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ: {index_path}")
        embeddings = OpenAIEmbeddings()
        vs = FAISS.load_local(str(index_path), embeddings)
        return vs, len(vs.docstore._dict)
    
    print(f"ìƒˆ ì¸ë±ìŠ¤ êµ¬ì¶•: {folder_id}")
    files = fetch_pdfs_from_drive(folder_id)
    if not files:
        raise ValueError(f"í´ë” {folder_id}ì—ì„œ PDFë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    all_docs = []
    for f in files:
        try:
            pdf_path = download_pdf(f["id"], f["name"])
            docs = process_pdf(pdf_path)
            for doc in docs:
                doc.metadata.update({
                    "gdrive_id": f["id"],
                    "gdrive_name": f["name"],
                    "modified": f.get("modifiedTime", "")
                })
            all_docs.extend(docs)
            print(f"ì²˜ë¦¬ ì™„ë£Œ: {f['name']} ({len(docs)} chunks)")
        except Exception as e:
            print(f"ì˜¤ë¥˜ {f['name']}: {e}")
    
    if not all_docs:
        raise ValueError("ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    embeddings = OpenAIEmbeddings()
    vs = FAISS.from_documents(all_docs, embeddings)
    vs.save_local(str(index_path))
    print(f"ì¸ë±ìŠ¤ ì €ì¥: {index_path}")
    return vs, len(all_docs)

def make_qa(vs: FAISS, k: int) -> RetrievalQA:
    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0)
    qa = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vs.as_retriever(search_kwargs={"k": k}),
        chain_type="stuff",
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    return qa

# ========= ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ =========
def analyze_uploaded_image(image, use_ocr=False, extra_context="", analysis_type="standard", icon_json=""):
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    if image is None:
        return "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    try:
        # PIL Imageë¡œ ë³€í™˜
        if hasattr(image, 'convert'):
            pil_img = image
        else:
            pil_img = Image.fromarray(image)
        
        # ë¶„ì„ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if analysis_type == "aws_architecture":
            result = analyze_aws_architecture(pil_img, detailed=True, include_recommendations=True)
        elif use_ocr:
            result = analyze_image_or_ocr(pil_img, ocr=True, extra_context=extra_context, icon_json=icon_json)
        else:
            result = analyze_image(pil_img, extra_context=extra_context, icon_json=icon_json)
        
        return result
    except Exception as e:
        return f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ========= Gradio í•¸ë“¤ëŸ¬ =========
class RagApp:
    def __init__(self):
        self.vs: Optional[FAISS] = None
        self.qa: Optional[RetrievalQA] = None
        self.k: int = 5
        self.last_build_info = ""

    def ensure_index(self, folder_id: str, force: bool = False) -> str:
        if force or self.vs is None:
            t0 = time.time()
            self.vs, n = build_or_load_vectorstore(folder_id)
            self.qa = make_qa(self.vs, self.k)
            self.last_build_info = f"ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ (k={self.k}, chunks={n}, folder={folder_id}, {time.time()-t0:.1f}s)"
        elif self.qa is None:
            self.qa = make_qa(self.vs, self.k)
        return self.last_build_info

    def set_k(self, k: int) -> str:
        self.k = int(k)
        if self.vs:
            self.qa = make_qa(self.vs, self.k)
        return f"k={self.k} ì„¤ì • ì™„ë£Œ"

    def ask(self, message: str, history: List[List[str]]) -> str:
        if not self.qa:
            self.ensure_index(FOLDER_ID, force=False)
        resp = self.qa.invoke({"query": message})
        answer = resp.get("result", "").strip()
        sources = resp.get("source_documents", []) or []
        # ì†ŒìŠ¤ 3ê°œê¹Œì§€ í‘œê¸°
        src_lines = []
        for i, d in enumerate(sources[:3], 1):
            m = d.metadata or {}
            src_lines.append(f"{i}. {m.get('gdrive_name','?')} (id={m.get('gdrive_id','?')}) p.{m.get('page', '?')}")
        if src_lines:
            answer += "\n\n[ì°¸ê³  ë¬¸ì„œ]\n" + "\n".join(src_lines)
        return answer

app = RagApp()

# ========= Gradio UI =========
with gr.Blocks(title="AWS Diagram RAG & Vision") as demo:
    gr.Markdown("### AWS ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ í•´ì„¤ RAG & Vision")
    
    with gr.Tabs():
        # RAG íƒ­
        with gr.TabItem("ğŸ“š ë¬¸ì„œ ê¸°ë°˜ RAG"):
            with gr.Row():
                folder_in = gr.Textbox(value=FOLDER_ID, label="Google Drive Folder ID")
                k_slider = gr.Slider(1, 10, value=5, step=1, label="Top-K(ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜)")
            with gr.Row():
                btn_build = gr.Button("ì¸ë±ìŠ¤(ì¬)êµ¬ì¶• / ë¡œë“œ")
                build_status = gr.Markdown("")
            chat = gr.Chatbot(height=420, label="LLM í•´ì„¤", type="messages")
            msg = gr.Textbox(placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ) ì´ ë‹¤ì´ì–´ê·¸ë¨ì˜ ë°ì´í„° íë¦„ì„ ì„¤ëª…í•´ì¤˜", label="ì§ˆë¬¸")
            with gr.Row():
                send_btn = gr.Button("ì „ì†¡", variant="primary")
                clear_btn = gr.Button("ëŒ€í™” ì§€ìš°ê¸°")

        # Vision íƒ­
        with gr.TabItem("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„"):
            with gr.Row():
                with gr.Column(scale=1):
                    image_input = gr.Image(label="AWS ë‹¤ì´ì–´ê·¸ë¨ ì—…ë¡œë“œ", type="pil")
                    with gr.Row():
                        analysis_type = gr.Radio(
                            choices=["standard", "aws_architecture"], 
                            value="aws_architecture",
                            label="ë¶„ì„ íƒ€ì…",
                            info="AWS ì•„í‚¤í…ì²˜: ì „ë¬¸ì  ë¶„ì„, Standard: ê¸°ë³¸ ë¶„ì„"
                        )
                        ocr_checkbox = gr.Checkbox(label="OCR ì‚¬ìš©", value=False)
                    analyze_btn = gr.Button("ì´ë¯¸ì§€ ë¶„ì„", variant="primary")
                    extra_context = gr.Textbox(
                        label="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)", 
                        placeholder="ì¶”ê°€ì ì¸ ì •ë³´ë‚˜ íŠ¹ë³„í•œ ìš”êµ¬ì‚¬í•­ì´ ìˆë‹¤ë©´ ì…ë ¥í•˜ì„¸ìš”",
                        lines=3
                    )
                    icon_json = gr.Textbox(
                        label="ì•„ì´ì½˜ íƒì§€ JSON (ì„ íƒì‚¬í•­)", 
                        placeholder="ì•„ì´ì½˜ íƒì§€ ê²°ê³¼ JSONì„ ì…ë ¥í•˜ì„¸ìš”",
                        lines=3
                    )
                with gr.Column(scale=1):
                    analysis_output = gr.Textbox(
                        label="ë¶„ì„ ê²°ê³¼", 
                        lines=20, 
                        max_lines=30,
                        interactive=False
                    )

    def on_build(fid, k):
        app.set_k(int(k))
        return app.ensure_index(fid, force=True)

    def on_send(message, history, fid, k):
        # history: [{"role":"user","content":"..."}, {"role":"assistant","content":"..."} ...]
        if not message:
            return gr.update(), history
        if not app.qa:
            app.set_k(int(k))
            app.ensure_index(fid, force=False)

        answer = app.ask(message, history)
        # ë©”ì‹œì§€ ë‘ ê°œ append (user, assistant)
        history = history + [
            {"role": "user", "content": message},
            {"role": "assistant", "content": answer},
        ]
        return "", history

    def on_k_change(k):
        return app.set_k(int(k))

    def on_analyze_image(image, use_ocr, context, analysis_type, icon_json):
        return analyze_uploaded_image(image, use_ocr, context, analysis_type, icon_json)
    
    def on_image_upload(image):
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ì´ˆê¸°í™”"""
        if image is not None:
            return gr.update(value=""), gr.update(value="")  # extra_context, icon_json ì´ˆê¸°í™”
        return gr.update(), gr.update()

    # RAG íƒ­ ì´ë²¤íŠ¸
    btn_build.click(on_build, inputs=[folder_in, k_slider], outputs=[build_status])
    k_slider.release(on_k_change, inputs=[k_slider], outputs=[build_status])
    send_btn.click(on_send, inputs=[msg, chat, folder_in, k_slider], outputs=[msg, chat])
    msg.submit(on_send, inputs=[msg, chat, folder_in, k_slider], outputs=[msg, chat])
    clear_btn.click(lambda: [], None, chat, queue=False)
    
    # Vision íƒ­ ì´ë²¤íŠ¸
    analyze_btn.click(
        on_analyze_image, 
        inputs=[image_input, ocr_checkbox, extra_context, analysis_type, icon_json], 
        outputs=[analysis_output]
    )
    
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ë°•ìŠ¤ ì´ˆê¸°í™”
    image_input.change(
        on_image_upload,
        inputs=[image_input],
        outputs=[extra_context, icon_json]
    )

if __name__ == "__main__":
    # ìµœì´ˆ í•œ ë²ˆ ë¡œë“œ ì‹œë„(ìºì‹œê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë¡œë“œ)
    try:
        app.ensure_index(FOLDER_ID, force=False)
    except Exception as e:
        print("[WARN] ì¸ë±ìŠ¤ ì´ˆê¸° ë¡œë“œ ì‹¤íŒ¨:", e)
    demo.launch(server_name="0.0.0.0", server_port=7860)
